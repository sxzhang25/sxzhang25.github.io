---
layout: post
title: "dr. ruha benjamin's <i>race after technology</i>"
date: 2020-08-17
tags: social-technology
refs:
---

About a month ago, I finished reading <i>Race After Technology: Abolitionist Tools for the New Jim Code</i> by <a href="https://www.ruhabenjamin.com/">Dr. Ruha Benjamin,</a> an Associate Professor in Princeton University's <a href="https://aas.princeton.edu/">Department of African American Studies.</a> The book talks about a lot of forms of discrimination in tech that I had known about or been aware of already, but dives deeper into the insidious consequences that these biases have in communities of color. I wanted to take some time after finishing the book to integrate her discussion of these issues into my own work and daily life before recording my thoughts. <!--excerpt-->Now, I can definitely say that the discourse within her book has given me a sharper critical eye towards how I approach the intended and unintended uses of various projects I get exposed to at work, especially as a software engineer on a computer vision team. Here are my biggest takeaways.

<h3>1. technology != positive change</h3>

One of the biggest problems in technology today is that, rather than being an equalizer of sorts, it often enhances existing social disparaties. Growing up, I had always been taught to view technology as a harbinger of social progress and an improved quality of life. I never really felt the need to explicitly question this perspective, even when stories of privacy breaches or digital warfare took center stage in the news cycle. Usually, my instinct would be to blame the user for not knowing how to properly use a supposedly neutral technological tool, or to blame the villain of the story for purposefully using technology with malicious intent. However, Dr. Benjamin immediately questions this notion with the her definition of "a new Jim Code," that is,

<blockquote>
<div class="quote">
    “the employment of new technologies that reflect and reproduce existing inequities but that are promoted and perceived as more objective or progressive than the discriminatory systems of a previous era.”
</div>
<br>
<div class="cite">Excerpt From: Ruha Benjamin. “Race After Technology.” Apple Books. <a href="https://books.apple.com/us/book/race-after-technology/id1472434033">https://books.apple.com/us/book/race-after-technology/id1472434033</a></div>
</blockquote>

As I continued to read, my instinct to immediately react to new technologies positively became clearer. Every time Dr. Benjamin brought up a different example of an app or software, I caught myself reflexively thinking, <i>wow, that's extremely impressive.</i> When Dr. Benjamin criticized a fancy new AI system, my first reaction was to feel defensive. It was almost as if a criticism of technology was a criticism of myself, because I consider myself a part of the scientific community. In reality, I know that her objections are mainly targeted at the systems in place within our society, which ultimately influence our scientific values. Such criticisms should be embraced, not rebutted. And to be clear, I don't think the point is that we should make a complete 180 degree turn and immediately reject every new scientific development that comes along; rather, we should practice holding our immense technological accomplishments to an even higher societal standard. Adopting this new mindset is something I still need to work on---it's not easy, especially for someone who has been given so many opportunities as a result of my embrace of digital technology. One thing I have been leaning on to help with this is my background in design, since conversations in design tend to more easily integrate discussions around accountability, accessibility, and inclusion. Design also plays a huge role in industry, which is often where technology's largest impacts come from, so I think that studying design is relevant in its own right as well.

<h3>2. the digital divide is (still) a serious issue</h3>

The ubiquity of technology is often used as a marker of how developed or advanced a society is. I think there is some merit to this; some of the main benefits of technology are increased efficiency and interconnectivity. However, as our lifestyles become increasingly dependent on technology, those who have not gained access to or have been implicitly barred access from these systems have a harder time participating. Even more concerning is the power of tech distributors or oversight commitees to impose conditional participation in this society. For example, Chinese journalists who have written critically about the government <a href="https://www.wired.co.uk/article/china-social-credit-system-explained">have been blacklisted</a> from transportation and financial services because their work is in conflict with the rules of the social credit system. In many ways, the US credit system also <a href="https://www.vox.com/the-goods/2018/11/2/18057450/china-social-credit-score-spend-frivolously-video-games">operates in a similar manner.</a> I think the following quote from the book captures this concisely:

<blockquote>
<div class="quote">
    “In theory, you are supposed to have the freedom to choose but in reality, the choice will only be whether to be left out or left behind.”
</div>
<br>
<div class="cite">Excerpt From: Ruha Benjamin. “Race After Technology.” Apple Books. <a href="https://books.apple.com/us/book/race-after-technology/id1472434033">https://books.apple.com/us/book/race-after-technology/id1472434033</a></div>
</blockquote>

The context in which I've always heard about the digital divide is within education. Especially during this pandemic, the lack of digital resources in underserved public schools has made remote learning <a href="https://gizmodo.com/the-pandemic-exposed-a-massive-digital-divide-in-our-sc-1844323273">extremely difficult.</a> While digital communications technology may not be inherently biased, it's clear that unequal access to positive digital resources has just as significant of an impact as so directly harmful technologies.

<h3>3. digital literacy needs to become a priority</h3>

As someone who has always approached technology from a very quantitative and technical perspective, it was important for me to hear such jarring social experiences with the way we use technology. At the heart of preventing and correcting the worst ways in which we experience technology is policy. Regulations and policies which clearly outline how technology should and <i>shouldn't</i> be used, how thorough our testing and vetting of software should be, and what kinds of social standards we should hold our research to is clearly important. However, I can't help but feel as if many of the people at the center of these discussions lack some of the knowledge of how these technical systems work in the first place, whether it's <a href="https://www.cnet.com/news/some-senators-in-congress-capitol-hill-just-dont-get-facebook-and-mark-zuckerberg/">the business models of social media giants</a> or simply <a href="https://www.vice.com/en_uk/article/z3ew8w/gop-congressman-turns-antitrust-hearing-into-personal-tech-support-session">the way email works.</a> Obviously, not everyone can be an expert in everything, and I think that requiring all lawmakers to know the ins and outs of Silicon Valley and computers and networks is completely unreasonable. But I do think that the body of legislators that regulate and oversee science and technology companies should include more people who have either deeper technical expertise, or who have more intimately experienced the troubling side effects (and direct effects) that new technologies have created. For me, I also feel a converse responsibility---as a scientist or engineer, realizing that I will one day be working on projects which have real life impact on real life citizens, and making the social ramifications of my technical work an equally important part of the job. It's definitely a two-way street.

<h3>afterthoughts</h3>

I think I will probably need to come back to this book and reread it at some point in the future. There are too many accounts, examples, and topics covered in one book for me to absorb everything in one read. I'm sure racial biases and lack of inclusivity are just a few immediate issues that the state of technology in the US suffers from, and it's going to take some time for me to unlearn the current way I think about these problems. For anyone interested in learning more, I think this book is an extremely great place to start. Dr. Benjamin writes in a way that is not sugar-coated, but very digestible. The entire book is packed with evidence. Of course, reading a single book might not make a huge impact in the long-run, but I think the great thing about books is that the reader <i>must</i> listen to the author, give them their undivided attention, and allow the author and subjects of the text to speak without being interrupted. If anything, reading this book has forced me to listen to the experiences of those who typically don't control the digital narrative.

<h3>lastly...</h3>

...remember to register to vote! Some sites I've found useful to learn more about registrating, vote-by-mail and candidate information are <a href="https://votesaveamerica.com/">Vote Save America</a> and <a href="https://turbovote.org/">TurboVote.</a>

<br>